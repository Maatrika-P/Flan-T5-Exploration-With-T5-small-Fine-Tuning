{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "articles and their corresponding summaries merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles and summaries have been merged and saved to merged_business.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the paths to the folders containing articles and summaries\n",
    "articles_folder = \"BBC News Summary/News Articles/business\"  # Replace with the actual folder path\n",
    "summaries_folder = \"BBC News Summary/Summaries/business\"  # Replace with the actual folder path\n",
    "\n",
    "# Define the path to the output CSV file\n",
    "output_csv_file = \"merged_business.csv\"\n",
    "\n",
    "# Initialize a list to store articles and summaries\n",
    "article_paths = []\n",
    "summary_paths = []\n",
    "\n",
    "# Get a list of article and summary file paths\n",
    "for i in range(1, 101):  # Assuming the files are named from \"001.txt\" to \"510.txt\"\n",
    "    article_file = f\"{i:03d}.txt\"  # Format the article file name\n",
    "    article_path = os.path.join(articles_folder, article_file)\n",
    "    article_paths.append(article_path)\n",
    "\n",
    "    # Construct the path to the corresponding summary file\n",
    "    summary_file = f\"{i:03d}.txt\"  # Format the summary file name\n",
    "    summary_path = os.path.join(summaries_folder, summary_file)\n",
    "    summary_paths.append(summary_path)\n",
    "\n",
    "# Write articles and summaries to a CSV file\n",
    "with open(output_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write header row\n",
    "    writer.writerow([\"articles\", \"summaries\"])\n",
    "\n",
    "    # Match articles with their corresponding summaries and write them to the CSV file\n",
    "    for article_path, summary_path in zip(article_paths, summary_paths):\n",
    "        with open(article_path, \"r\", encoding=\"utf-8\") as article_file, open(summary_path, \"r\", encoding=\"utf-8\") as summary_file:\n",
    "            article_content = article_file.read()\n",
    "            summary_content = summary_file.read()\n",
    "            writer.writerow([article_content, summary_content])\n",
    "\n",
    "print(f\"Articles and summaries have been merged and saved to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only articles / summaries merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles have been saved to business_summaries_t5.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the path to the folder containing articles\n",
    "articles_folder = \"BBC News Summary/Summaries/business\"  # Replace with the actual folder path\n",
    "\n",
    "# Define the path to the output CSV file for articles\n",
    "output_csv_file = \"business_summaries_t5.csv\"\n",
    "\n",
    "# Initialize a list to store articles\n",
    "article_paths = []\n",
    "\n",
    "# Get a list of article file paths\n",
    "for i in range(1, 51):  # Assuming the files are named from \"001.txt\" to \"510.txt\"\n",
    "    article_file = f\"{i:03d}.txt\"  # Format the article file name\n",
    "    article_path = os.path.join(articles_folder, article_file)\n",
    "    article_paths.append(article_path)\n",
    "\n",
    "# Write articles to a CSV file\n",
    "with open(output_csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write header row\n",
    "    writer.writerow([\"Actual\"])\n",
    "\n",
    "    # Write articles to the CSV file\n",
    "    for article_path in article_paths:\n",
    "        with open(article_path, \"r\", encoding=\"utf-8\") as article_file:\n",
    "            article_content = article_file.read()\n",
    "            writer.writerow([article_content])\n",
    "\n",
    "print(f\"Articles have been saved to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\SMA\\datasetcompilation.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/SMA/datasetcompilation.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SMA/datasetcompilation.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Check if GPU is available\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/SMA/datasetcompilation.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mtest\u001b[39m.\u001b[39mgpu_device_name():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:40:02.289968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:02.290229: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:02.290357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is configured to use\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 09:40:13.293027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:13.293451: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:13.293623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:13.293842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:13.293980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-18 09:40:13.294069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2129 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x7fe1db1a3430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set GPU memory growth before initializing TensorFlow\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"GPU is configured to use\")\n",
    "\n",
    "# Initialize TensorFlow (call this only once in your script)\n",
    "tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "#initialize the pre-trained model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking generation of one article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "US media giant Time Warner has reported a 76% jump in profits for the fourth quarter, helped by sales of high-speed internet connections and higher advert sales, compared with a year-ago period.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the article for which you want to generate a summary\n",
    "article = \"Ad sales boost Time Warner profit Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding. Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility, chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\"\n",
    "\n",
    "# Initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "# Generate a summary for the provided article\n",
    "inputs = tokenizer(\"summarize: \" + article, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "summary_ids = model.generate(inputs.input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 articles. 24 articles remaining.\n",
      "Processed 2 articles. 23 articles remaining.\n",
      "Processed 3 articles. 22 articles remaining.\n",
      "Processed 4 articles. 21 articles remaining.\n",
      "Processed 5 articles. 20 articles remaining.\n",
      "Processed 6 articles. 19 articles remaining.\n",
      "Processed 7 articles. 18 articles remaining.\n",
      "Processed 8 articles. 17 articles remaining.\n",
      "Processed 9 articles. 16 articles remaining.\n",
      "Processed 10 articles. 15 articles remaining.\n",
      "Processed 11 articles. 14 articles remaining.\n",
      "Processed 12 articles. 13 articles remaining.\n",
      "Processed 13 articles. 12 articles remaining.\n",
      "Processed 14 articles. 11 articles remaining.\n",
      "Processed 15 articles. 10 articles remaining.\n",
      "Processed 16 articles. 9 articles remaining.\n",
      "Processed 17 articles. 8 articles remaining.\n",
      "Processed 18 articles. 7 articles remaining.\n",
      "Processed 19 articles. 6 articles remaining.\n",
      "Processed 20 articles. 5 articles remaining.\n",
      "Processed 21 articles. 4 articles remaining.\n",
      "Processed 22 articles. 3 articles remaining.\n",
      "Processed 23 articles. 2 articles remaining.\n",
      "Processed 24 articles. 1 articles remaining.\n",
      "Processed 25 articles. 0 articles remaining.\n",
      "Processed 26 articles. 24 articles remaining.\n",
      "Processed 27 articles. 23 articles remaining.\n",
      "Processed 28 articles. 22 articles remaining.\n",
      "Processed 29 articles. 21 articles remaining.\n",
      "Processed 30 articles. 20 articles remaining.\n",
      "Processed 31 articles. 19 articles remaining.\n",
      "Processed 32 articles. 18 articles remaining.\n",
      "Processed 33 articles. 17 articles remaining.\n",
      "Processed 34 articles. 16 articles remaining.\n",
      "Processed 35 articles. 15 articles remaining.\n",
      "Processed 36 articles. 14 articles remaining.\n",
      "Processed 37 articles. 13 articles remaining.\n",
      "Processed 38 articles. 12 articles remaining.\n",
      "Processed 39 articles. 11 articles remaining.\n",
      "Processed 40 articles. 10 articles remaining.\n",
      "Processed 41 articles. 9 articles remaining.\n",
      "Processed 42 articles. 8 articles remaining.\n",
      "Processed 43 articles. 7 articles remaining.\n",
      "Processed 44 articles. 6 articles remaining.\n",
      "Processed 45 articles. 5 articles remaining.\n",
      "Processed 46 articles. 4 articles remaining.\n",
      "Processed 47 articles. 3 articles remaining.\n",
      "Processed 48 articles. 2 articles remaining.\n",
      "Processed 49 articles. 1 articles remaining.\n",
      "Processed 50 articles. 0 articles remaining.\n",
      "Predicted summaries appended to business_summaries.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#define the path to the input CSV file containing articles\n",
    "input_csv_file = \"business_articles.csv\"\n",
    "\n",
    "#define the path to the output CSV file with predicted summaries\n",
    "output_csv_file = \"business_summaries.csv\"\n",
    "\n",
    "#define the maximum chunk size for processing (adjust as needed)\n",
    "chunk_size = 25\n",
    "\n",
    "#initialize a list to store articles and predicted summaries\n",
    "article_chunks = []\n",
    "predicted_summary_chunks = []\n",
    "\n",
    "#read the input CSV in chunks and generate summaries\n",
    "total_articles = 0\n",
    "for chunk in pd.read_csv(input_csv_file, chunksize=chunk_size):\n",
    "    articles = chunk[\"Actual\"].tolist()\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(articles, 1):\n",
    "        inputs = tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "        total_articles += 1\n",
    "        print(f\"Processed {total_articles} articles. {len(articles) - i} articles remaining.\")\n",
    "\n",
    "    article_chunks.extend(articles)\n",
    "    predicted_summary_chunks.extend(summaries)\n",
    "\n",
    "#read the existing CSV file with actual summaries\n",
    "existing_data = pd.read_csv(output_csv_file)\n",
    "\n",
    "#create a DataFrame with articles and predicted summaries\n",
    "output_data = pd.DataFrame({\"Actual\": existing_data[\"Actual\"], \"predicted\": predicted_summary_chunks})\n",
    "\n",
    "#save the DataFrame to the output CSV file\n",
    "output_data.to_csv(output_csv_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Predicted summaries appended to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BertScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cumulative BERT Scores:\n",
      "Precision: 0.8984292471408843\n",
      "Recall: 0.7776961767673493\n",
      "F1 Score: 0.8332022118568421\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "df = pd.read_csv(\"business_summaries.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references = df[\"Actual\"].tolist()\n",
    "\n",
    "#compute BERT scores for each pair of actual and predicted values\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "\n",
    "#extract individual BERT scores (precision, recall, F1) for each pair\n",
    "precision = results[\"precision\"]\n",
    "recall = results[\"recall\"]\n",
    "f1 = results[\"f1\"]\n",
    "\n",
    "#create a new DataFrame to store the BERT scores\n",
    "output_df = pd.DataFrame({\"Actual\": references, \"Predicted\": predictions, \"Precision\": precision, \"Recall\": recall, \"F1\": f1})\n",
    "\n",
    "#save the BERT scores to a new CSV file\n",
    "output_df.to_csv(\"bert_scores_output.csv\", index=False)\n",
    "\n",
    "#calculate the final cumulative BERT scores\n",
    "final_precision = sum(precision) / len(precision)\n",
    "final_recall = sum(recall) / len(recall)\n",
    "final_f1 = sum(f1) / len(f1)\n",
    "\n",
    "#print the final cumulative BERT scores\n",
    "print(\"Final Cumulative BERT Scores:\")\n",
    "print(\"Precision:\", final_precision)\n",
    "print(\"Recall:\", final_recall)\n",
    "print(\"F1 Score:\", final_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROUGE Score\n",
    "\n",
    "1. ROUGE-1: Measures the overlap of unigrams (single words) between the generated text and the reference text.\n",
    "2. ROUGE-2: Measures the overlap of bigrams (pairs of consecutive words) between the generated text and the reference text.\n",
    "3. ROUGE-L: Measures the longest common subsequence between the generated text and the reference text, taking word order into account.\n",
    "4. ROUGE-Lsum: Similar to ROUGE-L, but it computes an F1 score for the entire document rather than just the longest subsequence.\n",
    "\n",
    "The ROUGE scores range from 0 to 1, with higher scores indicating better quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE-1: 0.3531693202756071\n",
      "ROUGE-2: 0.27901281130255196\n",
      "ROUGE-L: 0.2990974295461166\n",
      "ROUGE-Lsum: 0.2978857126523605\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "rouge = load('rouge')\n",
    "\n",
    "df = pd.read_csv(\"business_summaries.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references = df[\"Actual\"].tolist()\n",
    "\n",
    "#compute ROUGE scores for each pair of actual and predicted values\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "#save the ROUGE scores to a new CSV file\n",
    "output_df = pd.DataFrame({\"Actual\": references, \"Predicted\": predictions, \"ROUGE-1\": results['rouge1'], \"ROUGE-2\": results['rouge2'], \"ROUGE-L\": results['rougeL'], \"ROUGE-Lsum\": results['rougeLsum']})\n",
    "\n",
    "output_df.to_csv(\"rouge_scores_output.csv\", index=False)\n",
    "\n",
    "#print the ROUGE scores\n",
    "print(\"ROUGE Scores:\")\n",
    "print(\"ROUGE-1:\", results['rouge1'])\n",
    "print(\"ROUGE-2:\", results['rouge2'])\n",
    "print(\"ROUGE-L:\", results['rougeL'])\n",
    "print(\"ROUGE-Lsum:\", results['rougeLsum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEU Score \n",
    "\n",
    "ranging btw (0-1) higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.7575197648448169\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#load BLEU score function from NLTK\n",
    "def compute_bleu_score(prediction, references):\n",
    "    return sentence_bleu(references, prediction)\n",
    "\n",
    "#read data from CSV file\n",
    "df = pd.read_csv(\"business_summaries.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references_list = df[\"Actual\"].apply(lambda x: [reference.strip() for reference in x.split(',')]).tolist()\n",
    "\n",
    "#compute BLEU scores for each pair of actual and predicted values\n",
    "bleu_scores = [compute_bleu_score(prediction, references) for prediction, references in zip(predictions, references_list)]\n",
    "\n",
    "#create a new DataFrame to store the BLEU scores\n",
    "output_df = pd.DataFrame({\"Actual\": df[\"Actual\"], \"Predicted\": predictions, \"BLEU Score\": bleu_scores})\n",
    "\n",
    "#save the BLEU scores to a new CSV file\n",
    "output_df.to_csv(\"bleu_scores_output.csv\", index=False)\n",
    "\n",
    "#calculate the average BLEU score\n",
    "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#print the average BLEU score\n",
    "print(\"Average BLEU Score:\", average_bleu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METEOR Score  \n",
    "\n",
    "ranging from (0-1) the higher the better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR Score: 0.21299650891559285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#define the path to the CSV file containing actual and predicted summaries\n",
    "csv_file_path = \"business_summaries.csv\"\n",
    "\n",
    "#load METEOR score function from NLTK\n",
    "def compute_meteor_score(prediction, reference):\n",
    "    return single_meteor_score(reference, prediction)\n",
    "\n",
    "#read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#extract actual and predicted values\n",
    "actual_summaries = df[\"Actual\"].tolist()\n",
    "predicted_summaries = df[\"Predicted\"].tolist()\n",
    "\n",
    "#initialize a list to store METEOR scores\n",
    "meteor_scores = []\n",
    "\n",
    "#tokenize actual and predicted summaries and compute METEOR scores\n",
    "for actual, predicted in zip(actual_summaries, predicted_summaries):\n",
    "    actual_tokens = word_tokenize(actual)\n",
    "    predicted_tokens = word_tokenize(predicted)\n",
    "    meteor_scores.append(compute_meteor_score(predicted_tokens, actual_tokens))\n",
    "\n",
    "#calculate the average METEOR score\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(f\"Average METEOR Score: {average_meteor_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mikip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mikip\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVING ALL THE SCORES TO THE MAIN CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): US media giant Time Warner has reported a 76% jump in profits for the fourth quarter, helped by sales of high-speed internet connections and higher advert sales, despite a profit dip at Warner Bros and less users for AOL.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The dollar has hit its highest level against the euro in almost three months after Federal Reserve head Alan Greenspan said the US trade deficit is set to stabilise and that the US government's willingness to curb spending could help to reduce it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The owners of embattled Russian oil giant Yukos are to ask Rosneft to pay back a $900m (£479m) loan after it bought its former production unit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): British Airways has blamed high fuel prices for a 40% drop in profits as it reported a pre-tax profit of £75m ($141m) compared with £125m a year earlier.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Shares in UK drinks and food firm Allied Domecq have risen on speculation that it could be the target of a takeover by France's Pernod Ricard.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Japan's economy teetered on the brink of a technical recession in the three months to September, figures show, suggesting a much more hesitant recovery than had previously been thought.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The US economy created fewer jobs than expected in January, but a fall in jobseekers pushed the unemployment rate to its lowest level in three years. But analysts said the growth was not as strong as could have been expected given the favourable economic conditions.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Finance minister Palaniappan Chidambaram has called for reform of the United Nations, the World Bank and the IMF ahead of the G7 meeting of seven leading industrialised nations on Friday.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Ethiopia produced 14.27 million tonnes of crops in 2004, 24% higher than in 2003 and 21% more than the average of the past five years, a report says. In 2003, crop production totalled 11.49 million tonnes.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): A US appeal court has thrown out a government claim accusing the country's biggest tobacco companies of covering up the effects of smoking in a 2-1 decision. The tobacco firms deny that they illegally conspired to promote smoking and defraud the public.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Ask Jeeves, once among the best-known names on the web, has become the third leading online search firm this week to thank a revival in internet advertising for improving fortunes.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Indonesia's government has confirmed it is considering raising fuel prices by as much as 30%, as it seeks to curb fuel subsidies and direct the money into aid programmes for the poor. But critics argue cutting subsidies will hurt the poorer families that his government says it wants to help.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Struggling Japanese car maker Mitsubishi Motors has struck a deal to supply French car maker Peugeot with 30,000 sports utility vehicles (SUVs) for sale in Europe. The two firms signed a Memorandum of Understanding, and say they expect to seal a final agreement by Spring 2005.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The Daily and Sunday Telegraph newspapers are axing 90 journalist jobs - 17% of their editorial staff - to fund an £150m investment in new printing facilities. The Telegraph Group says the cuts are needed to fund an £150m investment in new printing facilities.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Air passengers who are unable to board their flights because of overbooking, cancellations or flight delays can now demand greater compensation, according to new EU rules which come into force on Thursday.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): China's efforts to stop the economy from overheating by clamping down on credit will continue into 2005, state media report. The curbs were introduced earlier this year to ward off the risk that rapid expansion might lead to soaring prices. There were also fears that too much stress might be placed on the fragile banking system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The Italian food group at the centre of one of Europe's most painful corporate scandals has reported a doubling in profit. Its pre-tax earnings in the fourth quarter were 77m euros (£53m; $100m).\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): India's rupee has hit a five-year high after Standard & Poor's raised the country's foreign currency rating. The currency has gained almost 1% in the past three sessions.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): India has raised the limit for foreign direct investment in telecoms companies from 49% to 74% in a bid to boost the country's fast-growing mobile market, the government has announced.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Customers trying to get through to call centres are getting impatient and quicker to hang up, a survey suggests. Once past the welcome message, callers on average hang up after just 65 seconds of listening to canned music.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Leisure group Rank could unveil plans to demerge its film services unit and sell its media business, reports claim. Rank, formerly famous for the Carry On series, will expose the shake-up at the announcement of its results on Friday, the Sunday Telegraph reported.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The number of people out of work in Europe's largest economy has risen for the tenth straight month as growth remains stubbornly slow, according to official figures released by the Federal Labour Agency.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The French economy picked up speed at the end of 2004, official figures show - but still looks set to have fallen short of the government's hopes. But the good quarterly figures mark a continuing trend of improving indicators for the health of the economy.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The gap between US exports and imports hit an all-time high of $671.7bn (£484bn) in 2004, latest figures show. The Commerce Department said the deficit for all of last year was 24.4% above the previous record - 2003's imbalance of $496.5bn.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): A US judge has dismissed an attempt by Russian oil giant Yukos to gain bankruptcy protection in the US, a blow to efforts to get damages for the sale of its Yugansk division.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The world's biggest carmaker General Motors (GM) is recalling nearly 200,000 vehicles in the US on safety grounds, according to federal regulators. The largest recall involves 155,465 pickups, vans and sports utility vehicles (SUVs).\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Mittal Steel, one of the world's largest steel producers, could cut up to 45,000 jobs over the next five years, its chief executive has said. The Netherlands-based company is due to complete its $4.5bn acquisition of US firm ISG next month, making it one of the largest global firms of its kind.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Crude oil prices surged back above the $47 a barrel mark on Thursday after an energy market watchdog raised its forecasts for global demand. The International Energy Agency (IEA) warned demand for Opec's crude in the first quarter would outstrip supply.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Venezuelan authorities say they will seize farmland owned by a British company as part of President Chavez's agrarian reform programme. The Vestey Group has not been informed of any planned seizure.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): The soaring cost of oil has hit global economic growth, although world's major economies should weather the storm of price rises, according to the Organisation for Economic Co-operation and Development (OECD).\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Irish shares have risen to a record high, with investors persuaded to buy into the market by low inflation and strong growth forecasts. The ISEQ index closed up 23 points to 6661.89 on Thursday, fuelled by strong growth in banking and financial stocks.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Japan's Sumitomo Mitsui Financial has withdrawn its takeover offer for rival bank UFJ Holdings, clearing the way for the latter to merge with Mitsubishi Tokyo.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Half of the money put aside by the Colombian government to help the country's poor is benefiting people who do not need it, a study has found. A total of 24.2 trillion pesos ($10.2bn; £5.5bn) is earmarked for subsidies for the poor.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Some 2,000 jobs at MG Rover's Midlands plant may be cut if investment in the firm by a Chinese car maker goes ahead, the Financial Times has reported, citing sources close to the negotiations.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): UK advertising giant WPP has posted larger-than-expected annual profits and predicted that it will outperform the market in 2005. Pre-tax profits rose 15% from a year ago to reach £546m ($1.04bn).\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Foreign firms have been given an extra year to meet tough new corporate governance regulations imposed by the US stock market watchdog, the Securities and Exchange Commission has extended the deadline to get in line with the rules until 15 July 2006.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Yoshiaki Tsutsumi was once ranked as the world's richest man and ran a business spanning hotels, railways, construction and a baseball team.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): German telecoms firm Deutsche Telekom saw strong fourth quarter profits on the back of upbeat US mobile earnings and better-than-expected asset sales, a dramatic change from the loss of 364m euros in 2003.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Italy's Illva Saronno has agreed to buy 33% of Changyu, the largest wine maker in China, for £58.16m, once the government approves the deal.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): UK sportswear firm Umbro has posted a 222% rise in annual profit after sales of replica England football kits were boosted by the Euro 2004 tournament. Pre-tax profit for 2004 was £15.4m ($29.4m).\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Federal Reserve chairman Alan Greenspan has warned that allowing huge US budget deficits to continue could have \"severe\" consequences, according to a speech to the House Budget Committee.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Shares in UK Coal have fallen after the mining group reported losses had deepened to £51.6m in 2004 from £1.2m. The South Yorkshire company blamed geological problems, industrial action and \"operating flaws\" at its deep mines.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Saudi Arabia's foreign ministry will employ women for the first time this year, Foreign Minister Prince Saud Al-Faisal has been reported as saying. The move comes as the country inches open the door to working women.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Japan's economy has slipped back into recession for the fourth time in a decade, according to official figures released by the government's Cabinet Office on Wednesday. The Tokyo stock market fell after the figures were announced, but rose again on a widespread perception that the economy will recover.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): US light sweet crude futures jumped to $53.09 a barrel in New York before closing at $53.03 as a fire at a Texas refinery shut down petrol production.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Japan's industrial output fell in October while unemployment rose, casting further doubt on the strength of the country's economic recovery, according to official figures released by the ministry of economy, trade and industry.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Budget airline Ryanair has placed an order for 70 Boeing 737-800 planes, in a deal valued at $4bn (£2.1bn) which should lead to 2,500 new jobs.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Parmalat, the Italian dairy company which went bust after an accounting scandal, hopes to be back on the Italian stock exchange in July, the firm's administrators have said in a statement.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Less than four years after the new Mini was launched, German car maker BMW has announced £100m of new investment. Some 200 new jobs are to be created at the Oxford factory, including modernised machinery and a new body shell production building.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): A combination of bad weather, rising raw material costs and the sluggish European economy has hit sales at Swiss food and drink giant Nestle, which is to raise its dividend by 11%.\n",
      "Average METEOR Score: 0.0\n",
      "All scores saved to all_scores_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "#define the path to the CSV file containing actual and predicted summaries\n",
    "csv_file_path = \"business_summaries.csv\"\n",
    "\n",
    "#load BERTScore and ROUGE\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load('rouge')\n",
    "\n",
    "#read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#extract actual and predicted values\n",
    "actual_summaries = df[\"Actual\"].tolist()\n",
    "predicted_summaries = df[\"Predicted\"].tolist()\n",
    "\n",
    "#initialize lists to store scores\n",
    "bert_precision_scores = []\n",
    "bert_recall_scores = []\n",
    "bert_f1_scores = []\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "rouge_lsum_scores = []\n",
    "bleu_scores = []\n",
    "meteor_scores = []\n",
    "\n",
    "#compute scores for each pair of actual and predicted summaries\n",
    "for actual, predicted in zip(actual_summaries, predicted_summaries):\n",
    "    #compute BERTScores\n",
    "    bert_results = bertscore.compute(predictions=[predicted], references=[actual], model_type=\"distilbert-base-uncased\")\n",
    "    bert_precision_scores.append(bert_results[\"precision\"])\n",
    "    bert_recall_scores.append(bert_results[\"recall\"])\n",
    "    bert_f1_scores.append(bert_results[\"f1\"])\n",
    "\n",
    "    #compute ROUGE scores\n",
    "    rouge_result = rouge.compute(predictions=[predicted], references=[actual])\n",
    "\n",
    "    rouge_1_scores.append(rouge_result['rouge1'])\n",
    "    rouge_2_scores.append(rouge_result['rouge2'])\n",
    "    rouge_l_scores.append(rouge_result['rougeL'])\n",
    "    rouge_lsum_scores.append(rouge_result['rougeLsum'])\n",
    "\n",
    "    #compute BLEU score\n",
    "    references = [actual.split()]  #assuming the reference is a list of words\n",
    "    predicted_tokens = predicted.split()\n",
    "    bleu_score = sentence_bleu(references, predicted_tokens)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    #compute METEOR score\n",
    "    try:\n",
    "        meteor_score = single_meteor_score(references[0], predicted)  #use the METEOR function\n",
    "        meteor_scores.append(meteor_score)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating METEOR score: {e}\")\n",
    "        meteor_scores.append(0.0)  #assign a default score of 0.0 for errors\n",
    "\n",
    "#create a new DataFrame to store all the scores\n",
    "scores_df = pd.DataFrame({\n",
    "    \"Actual\": actual_summaries,\n",
    "    \"Predicted\": predicted_summaries,\n",
    "    \"BERT Precision\": bert_precision_scores,\n",
    "    \"BERT Recall\": bert_recall_scores,\n",
    "    \"BERT F1\": bert_f1_scores,\n",
    "    \"ROUGE-1 F1\": rouge_1_scores,\n",
    "    \"ROUGE-2 F1\": rouge_2_scores,\n",
    "    \"ROUGE-L F1\": rouge_l_scores,\n",
    "    \"ROUGE-Lsum F1\": rouge_lsum_scores,\n",
    "    \"BLEU Score\": bleu_scores,\n",
    "    \"METEOR Score\": meteor_scores\n",
    "})\n",
    "\n",
    "#calculate and print the average METEOR score\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(f\"Average METEOR Score: {average_meteor_score}\")\n",
    "\n",
    "#save all the scores to a new CSV file\n",
    "output_csv = \"all_scores_output.csv\"\n",
    "scores_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"All scores saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
