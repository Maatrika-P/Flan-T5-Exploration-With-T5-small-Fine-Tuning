{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5-small-model\\\\tokenizer_config.json',\n",
       " 't5-small-model\\\\special_tokens_map.json',\n",
       " 't5-small-model\\\\spiece.model',\n",
       " 't5-small-model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "output_dir = \"t5-small-model\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE TUNING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [05:22<00:00, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 322.3023, 'train_samples_per_second': 0.745, 'train_steps_per_second': 0.093, 'train_loss': 1.9931191762288412, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30, training_loss=1.9931191762288412, metrics={'train_runtime': 322.3023, 'train_samples_per_second': 0.745, 'train_steps_per_second': 0.093, 'train_loss': 1.9931191762288412, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "dataset = pd.read_csv('merged_business.csv')  \n",
    "\n",
    "#initialize your tokenizer and model based on the downloaded model\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small-model\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small-model\")\n",
    "\n",
    "#define the preprocess_function\n",
    "def preprocess_function(row):\n",
    "    article = row['articles']\n",
    "    summary = row['summaries']\n",
    "\n",
    "    #tokenize the article and summary\n",
    "    inputs = tokenizer(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    labels = tokenizer(summary, return_tensors=\"pt\", max_length=150, truncation=True)\n",
    "\n",
    "    return {\n",
    "        'input_ids': inputs['input_ids'].squeeze(),\n",
    "        'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "        'labels': labels['input_ids'].squeeze(),\n",
    "    }\n",
    "\n",
    "#apply the preprocess_function to tokenize the datasets\n",
    "tokenized_datasets = dataset.apply(preprocess_function, axis=1)\n",
    "\n",
    "#define the number of training examples based on your dataset size\n",
    "num_train_examples = int(len(tokenized_datasets) * 0.8)  # 80% for training\n",
    "\n",
    "#split your dataset into training and testing\n",
    "train_dataset = tokenized_datasets.iloc[:num_train_examples]\n",
    "test_dataset = tokenized_datasets.iloc[num_train_examples:]\n",
    "\n",
    "#data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "#fine-tuning arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"fine-tuned-t5-small-model\",  \n",
    "    overwrite_output_dir=True,  \n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    eval_steps=10_000,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    predict_with_generate=True,\n",
    ")\n",
    "\n",
    "#create a Seq2Seq Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=test_dataset,  \n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "#start the fine-tuning process\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING GENERATION OF ONE ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "time Warner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. its profits were buoyed by one-off gains which offset a profit dip. it lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "#load the fine-tuned model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"fine-tuned-t5-small-model\")  # Use the correct path to your fine-tuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"fine-tuned-t5-small-model\")  # Use the same path as above\n",
    "\n",
    "#input article\n",
    "input_article =  \"Ad sales boost Time Warner profit, Quarterly profits at US media giant TimeWarner jumped 76% to $1.13bn (Â£600m) for the three months to December, from $639m year-earlier. The firm, which is now one of the biggest investors in Google, benefited from sales of high-speed internet connections and higher advert sales. TimeWarner said fourth quarter sales rose 2% to $11.1bn from $10.9bn. Its profits were buoyed by one-off gains which offset a profit dip at Warner Bros, and less users for AOL. Time Warner said on Friday that it now owns 8% of search-engine Google. But its own internet business, AOL, had has mixed fortunes. It lost 464,000 subscribers in the fourth quarter profits were lower than in the preceding three quarters. However, the company said AOL's underlying profit before exceptional items rose 8% on the back of stronger internet advertising revenues. It hopes to increase subscribers by offering the online service free to TimeWarner internet customers and will try to sign up AOL's existing customers for high-speed broadband. TimeWarner also has to restate 2000 and 2003 results following a probe by the US Securities Exchange Commission (SEC), which is close to concluding. Time Warner's fourth quarter profits were slightly better than analysts' expectations. But its film division saw profits slump 27% to $284m, helped by box-office flops Alexander and Catwoman, a sharp contrast to year-earlier, when the third and final film in the Lord of the Rings trilogy boosted results. For the full-year, TimeWarner posted a profit of $3.36bn, up 27% from its 2003 performance, while revenues grew 6.4% to $42.09bn. Our financial performance was strong, meeting or exceeding all of our full-year objectives and greatly enhancing our flexibility, chairman and chief executive Richard Parsons said. For 2005, TimeWarner is projecting operating earnings growth of around 5%, and also expects higher revenue and wider profit margins. TimeWarner is to restate its accounts as part of efforts to resolve an inquiry into AOL by US market regulators. It has already offered to pay $300m to settle charges, in a deal that is under review by the SEC. The company said it was unable to estimate the amount it needed to set aside for legal reserves, which it previously set at $500m. It intends to adjust the way it accounts for a deal with German music publisher Bertelsmann's purchase of a stake in AOL Europe, which it had reported as advertising revenue. It will now book the sale of its stake in AOL Europe as a loss on the value of that stake.\"\n",
    "# Tokenize the input article\n",
    "input_ids = tokenizer(\"summarize: \" + input_article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "#generate a summary\n",
    "summary_ids = model.generate(input_ids.input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "#decode the generated summary\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "#print the generated summary\n",
    "print(\"Generated Summary:\")\n",
    "print(generated_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATING SUMMARIES OF ALL THE ARTICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 articles. 24 articles remaining.\n",
      "Processed 2 articles. 23 articles remaining.\n",
      "Processed 3 articles. 22 articles remaining.\n",
      "Processed 4 articles. 21 articles remaining.\n",
      "Processed 5 articles. 20 articles remaining.\n",
      "Processed 6 articles. 19 articles remaining.\n",
      "Processed 7 articles. 18 articles remaining.\n",
      "Processed 8 articles. 17 articles remaining.\n",
      "Processed 9 articles. 16 articles remaining.\n",
      "Processed 10 articles. 15 articles remaining.\n",
      "Processed 11 articles. 14 articles remaining.\n",
      "Processed 12 articles. 13 articles remaining.\n",
      "Processed 13 articles. 12 articles remaining.\n",
      "Processed 14 articles. 11 articles remaining.\n",
      "Processed 15 articles. 10 articles remaining.\n",
      "Processed 16 articles. 9 articles remaining.\n",
      "Processed 17 articles. 8 articles remaining.\n",
      "Processed 18 articles. 7 articles remaining.\n",
      "Processed 19 articles. 6 articles remaining.\n",
      "Processed 20 articles. 5 articles remaining.\n",
      "Processed 21 articles. 4 articles remaining.\n",
      "Processed 22 articles. 3 articles remaining.\n",
      "Processed 23 articles. 2 articles remaining.\n",
      "Processed 24 articles. 1 articles remaining.\n",
      "Processed 25 articles. 0 articles remaining.\n",
      "Processed 26 articles. 24 articles remaining.\n",
      "Processed 27 articles. 23 articles remaining.\n",
      "Processed 28 articles. 22 articles remaining.\n",
      "Processed 29 articles. 21 articles remaining.\n",
      "Processed 30 articles. 20 articles remaining.\n",
      "Processed 31 articles. 19 articles remaining.\n",
      "Processed 32 articles. 18 articles remaining.\n",
      "Processed 33 articles. 17 articles remaining.\n",
      "Processed 34 articles. 16 articles remaining.\n",
      "Processed 35 articles. 15 articles remaining.\n",
      "Processed 36 articles. 14 articles remaining.\n",
      "Processed 37 articles. 13 articles remaining.\n",
      "Processed 38 articles. 12 articles remaining.\n",
      "Processed 39 articles. 11 articles remaining.\n",
      "Processed 40 articles. 10 articles remaining.\n",
      "Processed 41 articles. 9 articles remaining.\n",
      "Processed 42 articles. 8 articles remaining.\n",
      "Processed 43 articles. 7 articles remaining.\n",
      "Processed 44 articles. 6 articles remaining.\n",
      "Processed 45 articles. 5 articles remaining.\n",
      "Processed 46 articles. 4 articles remaining.\n",
      "Processed 47 articles. 3 articles remaining.\n",
      "Processed 48 articles. 2 articles remaining.\n",
      "Processed 49 articles. 1 articles remaining.\n",
      "Processed 50 articles. 0 articles remaining.\n",
      "Predicted summaries appended to business_summaries_t5.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "#define the path to the input CSV file containing articles\n",
    "input_csv_file = \"business_articles.csv\"\n",
    "\n",
    "#define the path to the output CSV file with predicted summaries\n",
    "output_csv_file = \"business_summaries_t5.csv\"\n",
    "\n",
    "#define the maximum chunk size for processing (adjust as needed)\n",
    "chunk_size = 25\n",
    "\n",
    "#initialize a T5 model and tokenizer (use the path to your fine-tuned model)\n",
    "model_name = \"fine-tuned-t5-small-model\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "#initialize lists to store articles and predicted summaries\n",
    "article_chunks = []\n",
    "predicted_summary_chunks = []\n",
    "\n",
    "#read the input CSV in chunks and generate summaries\n",
    "total_articles = 0\n",
    "for chunk in pd.read_csv(input_csv_file, chunksize=chunk_size):\n",
    "    articles = chunk[\"Actual\"].tolist()\n",
    "    summaries = []\n",
    "\n",
    "    for i, article in enumerate(articles, 1):\n",
    "        input_text = \"summarize: \" + article\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "        total_articles += 1\n",
    "        print(f\"Processed {total_articles} articles. {len(articles) - i} articles remaining.\")\n",
    "\n",
    "    article_chunks.extend(articles)\n",
    "    predicted_summary_chunks.extend(summaries)\n",
    "\n",
    "#read the existing CSV file with actual summaries\n",
    "existing_data = pd.read_csv(output_csv_file)\n",
    "\n",
    "#create a DataFrame with articles and predicted summaries\n",
    "output_data = pd.DataFrame({\"Actual\": existing_data[\"Actual\"], \"Predicted\": predicted_summary_chunks})\n",
    "\n",
    "#save the DataFrame to the output CSV file\n",
    "output_data.to_csv(output_csv_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Predicted summaries appended to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cumulative BERT Scores:\n",
      "Precision: 0.86978520154953\n",
      "Recall: 0.7744840514659882\n",
      "F1 Score: 0.8189856839179993\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "df = pd.read_csv(\"business_summaries_t5.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references = df[\"Actual\"].tolist()\n",
    "\n",
    "#compute BERT scores for each pair of actual and predicted values\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "\n",
    "#extract individual BERT scores (precision, recall, F1) for each pair\n",
    "precision = results[\"precision\"]\n",
    "recall = results[\"recall\"]\n",
    "f1 = results[\"f1\"]\n",
    "\n",
    "#create a new DataFrame to store the BERT scores\n",
    "output_df = pd.DataFrame({\"Actual\": references, \"Predicted\": predictions, \"Precision\": precision, \"Recall\": recall, \"F1\": f1})\n",
    "\n",
    "#save the BERT scores to a new CSV file\n",
    "output_df.to_csv(\"bert_scores_output.csv\", index=False)\n",
    "\n",
    "#calculate the final cumulative BERT scores\n",
    "final_precision = sum(precision) / len(precision)\n",
    "final_recall = sum(recall) / len(recall)\n",
    "final_f1 = sum(f1) / len(f1)\n",
    "\n",
    "#print the final cumulative BERT scores\n",
    "print(\"Final Cumulative BERT Scores:\")\n",
    "print(\"Precision:\", final_precision)\n",
    "print(\"Recall:\", final_recall)\n",
    "print(\"F1 Score:\", final_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.6647678816485887\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#load BLEU score function from NLTK\n",
    "def compute_bleu_score(prediction, references):\n",
    "    return sentence_bleu(references, prediction)\n",
    "\n",
    "#read data from CSV file\n",
    "df = pd.read_csv(\"business_summaries_t5.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references_list = df[\"Actual\"].apply(lambda x: [reference.strip() for reference in x.split(',')]).tolist()\n",
    "\n",
    "#compute BLEU scores for each pair of actual and predicted values\n",
    "bleu_scores = [compute_bleu_score(prediction, references) for prediction, references in zip(predictions, references_list)]\n",
    "\n",
    "#create a new DataFrame to store the BLEU scores\n",
    "output_df = pd.DataFrame({\"Actual\": df[\"Actual\"], \"Predicted\": predictions, \"BLEU Score\": bleu_scores})\n",
    "\n",
    "#save the BLEU scores to a new CSV file\n",
    "output_df.to_csv(\"bleu_scores_output.csv\", index=False)\n",
    "\n",
    "#calculate the average BLEU score\n",
    "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#print the average BLEU score\n",
    "print(\"Average BLEU Score:\", average_bleu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROUGE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "ROUGE-1: 0.340177111036897\n",
      "ROUGE-2: 0.2352473718909039\n",
      "ROUGE-L: 0.2493709198443118\n",
      "ROUGE-Lsum: 0.24992097166199087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "\n",
    "rouge = load('rouge')\n",
    "\n",
    "df = pd.read_csv(\"business_summaries_t5.csv\")\n",
    "\n",
    "#extract actual and predicted values from the DataFrame\n",
    "predictions = df[\"Predicted\"].tolist()\n",
    "references = df[\"Actual\"].tolist()\n",
    "\n",
    "#compute ROUGE scores for each pair of actual and predicted values\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "#save the ROUGE scores to a new CSV file\n",
    "output_df = pd.DataFrame({\"Actual\": references, \"Predicted\": predictions, \"ROUGE-1\": results['rouge1'], \"ROUGE-2\": results['rouge2'], \"ROUGE-L\": results['rougeL'], \"ROUGE-Lsum\": results['rougeLsum']})\n",
    "\n",
    "output_df.to_csv(\"rouge_scores_output.csv\", index=False)\n",
    "\n",
    "#print the ROUGE scores\n",
    "print(\"ROUGE Scores:\")\n",
    "print(\"ROUGE-1:\", results['rouge1'])\n",
    "print(\"ROUGE-2:\", results['rouge2'])\n",
    "print(\"ROUGE-L:\", results['rougeL'])\n",
    "print(\"ROUGE-Lsum:\", results['rougeLsum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METEOR SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average METEOR Score: 0.20869762086067684\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#define the path to the CSV file containing actual and predicted summaries\n",
    "csv_file_path = \"business_summaries_t5.csv\"\n",
    "\n",
    "#load METEOR score function from NLTK\n",
    "def compute_meteor_score(prediction, reference):\n",
    "    return single_meteor_score(reference, prediction)\n",
    "\n",
    "#read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#extract actual and predicted values\n",
    "actual_summaries = df[\"Actual\"].tolist()\n",
    "predicted_summaries = df[\"Predicted\"].tolist()\n",
    "\n",
    "#initialize a list to store METEOR scores\n",
    "meteor_scores = []\n",
    "\n",
    "#tokenize actual and predicted summaries and compute METEOR scores\n",
    "for actual, predicted in zip(actual_summaries, predicted_summaries):\n",
    "    actual_tokens = word_tokenize(actual)\n",
    "    predicted_tokens = word_tokenize(predicted)\n",
    "    meteor_scores.append(compute_meteor_score(predicted_tokens, actual_tokens))\n",
    "\n",
    "#calculate the average METEOR score\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(f\"Average METEOR Score: {average_meteor_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING ALL SCORES TO THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): time Warner profits jumped 76% to $1.13bn (£600m) for the three months to December. it said fourth quarter sales rose 2% to $11.1bn from $10.9bn. its profits were buoyed by one-off gains which offset a profit dip.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): in late trading in new york, the dollar reached $1.2871 against the euro, from $1.2974 on Thursday. the u.s. government's willingness to curb spending and rising household savings are factors which may help to reduce it. concerns about the deficit concerns about China remain.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): state-owned Rosneft bought the Yugansk unit for $9.3bn in a sale forced by Russia to part settle a $27.5bn tax claim against Yukos. the company has said it intends to take action against menatep to recover some of the tax claims owed by Yugansk.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): high fuel prices hit BA's profits, reporting its results for the three months to 31 December 2004. the airline made a pre-tax profit of £75m ($141m) compared with £125m a year earlier. it expects a rise in full-year revenues.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Allied Domecq shares in London rose 4% by 1200 GMT. Pernod shares in Paris slipped 1.2%. pernod said it was seeking acquisitions but refused to comment on specifics.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): a common technical definition of a recession is two successive quarters of negative growth. a common technical definition of a recession is two successive quarters of negative growth. the government was keen to play down the worrying implications of the data.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): a fall in jobseekers pushed the unemployment rate to its lowest level in three years. the increase in non-farm payrolls was below market expectations of 190,000 new jobs. the gains mean that president bush can celebrate a net growth in jobs in the US economy.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): india's finance minister lashed out at the restrictive trade policies of the G7 nations. he objected to subsidies on agriculture that make it hard for developing nations like India to compete. he also called for reform of the u.n., the world bank and the IMF.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): in 2003 crop production totalled 11.49 million tonnes, a report says. 2.2 million Ethiopians will still need emergency assistance. agriculture is the main economic activity in Ethiopia, representing 45% of gross domestic product.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mikip\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the demand for $280bn (£155bn) - filed by the Clinton administration in 1999 - was rejected in a 2-1 decision. the case could not be brought under federal anti-racketeering laws.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the firm's revenue nearly tripled in the fourth quarter of 2004, exceeding $86m (£46m) the firm's $17m profit for the quarter was dwarfed by the $204m announced by rival Google earlier in the week.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): millions of Indonesians use kerosene for basic cooking. government has said it wants to curb fuel subsidies. critics argue cutting subsidies will hurt poorer families.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the two firms signed a Memorandum of Understanding. they expect to seal a final agreement by spring 2005. the alliance comes as a badly-needed boost for loss-making Mitsubishi.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the daily and Sunday Telegraph newspapers are axing 90 journalist jobs. the cuts are needed to fund an £150m investment in new printing facilities. the national union of Journalists has called on the management to recall the notice of redundancy by midday on Monday.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): new rules set compensation at between 250 euros (£173) and 600 euros, depending on the length of the flight. airlines have attacked the legislation saying they could be forced to push prices higher to cover the extra cost. the european commission is facing two legal challenges.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the curbs were introduced earlier this year to ward off the risk that rapid expansion might lead to soaring prices. there were also fears that too much stress might be placed on the fragile banking system. the breakneck pace of economic expansion has kept growth above 9% for more than a year.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): parmalat's pre-tax earnings in the fourth quarter were 77m euros (£53m; $100m), up from 38m in the same period of 2003. the firm had been fined 11m euros for having violated takeover rules five years ago. its debt is close to 12bn euros, and is falling only slowly.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the rupee climbed to 43.305 per US dollar on Thursday, up from a close of 43.41. the currency has gained almost 1% in the past three sessions. more cash is expected to flow into its markets, buoying the rupee.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the government hopes to increase the number of mobile users from 95 million to between 200 and 250 million by 2007. the decision to raise the limit for foreign investors faced considerable opposition from the communist parties. potential foreign investors will however need government approval before they increase their stake beyond 49%.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): call centres have a high \"churn rate\" with nearly a quarter of workers throwing in the towel every year. the number of calls to call centres is growing at a rate of 20% every year. the number of calls to call centres is growing at a rate of 20%.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Rank, formerly famous for the Carry On series, will expose the shake-up at the announcement of its results on Friday. Advisors Goldman Sachs are understood to have valued its demerged Deluxe Film unit at £300m. speculation of a possible shake-up has mounted since Rank announced a study into a possible demerger in September.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): german unemployment rose 7,000 in November to 4.464 million people, or 10.8% of the workforce. but officials say stagnant growth is still stifling the job market. the brunt of the unemployment is still being felt in the eastern part of Germany.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): growth for the three months to December was a seasonally-adjusted 0.7-0.8%, ahead of the 0.6% forecast. if confirmed, that would be the best quarterly showing since early 2002. the good quarterly figures mark a continuing trend of improving indicators for the health of the French economy.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the gap between US exports and imports hit an all-time high of $671.7bn (£484bn) in 2004. the deficit with China, up 30.5% at $162bn, was the largest ever recorded with a single country. but on a monthly basis the US trade gap narrowed by 4.9% in December to £56.4bn.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the court ruling is a blow to efforts to get damages for the sale of Yugansk. former Yukos boss Mikhail Khodorkovsky began testimony on friday. he pleaded not guilty to charges brought against him and denied involvement in any criminal activities.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the largest recall involves 155,465 pickups, vans and sports utility vehicles. the affected vehicles are from the 2004 and 2005 model years, GM said. a pressure accumulator in the braking system could crack during normal driving.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): mittal steel is one of the world's largest steel producers. it is due to complete its $4.5bn acquisition of US firm ISG next month. the company will aim to reduce its workforce by between 7,000 and 8,000 annually.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the IEA warned demand for Opec's crude in the first quarter would outstrip supply. the IEA raised its estimate of 2005 oil demand growth by 80,000 barrels a day. the fresh rally in crude prices followed gains on Wednesday triggered by large falls in US crude supplies.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): officials say farmland owned by a subsidiary of the Vestey Group will be taken and used to settle poor farmers. the government is cracking down on so-called latifundios, or large rural estates, which it says are lying idle. the firm insisted that it had complied fully with Venezuelan law.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the OECD cut its growth predictions for the world's main industrialised regions. the soaring cost of oil has hit global economic growth, the OECD says. despite recent oil price turbulence the world economy will regain momentum.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the ISEQ index of leading shares closed up 23 points to 6661.89 on Thursday. a fall in the rate of inflation to 2.3% in January gave a fresh boost to shares which have advanced 4% this month. the economy is set for strong growth in 2005 while interest rates remain low.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): sumitomo mitsui financial withdraws takeover offer for rival bank UFJ Holdings. deal would create world's biggest bank with assets of about 189 trillion yen ($1.8 trillion) sumitomo's exit ends the most high profile fight in Japanese bank history.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): a total of 24.2 trillion pesos ($10.2bn; £5.5bn) is earmarked for subsidies for the poor. but 12.1 trillion pesos is going to the richest part of the population, rather than those in need. sound distribution of the cash could cut poverty levels to 36% from 53%.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): some 2,000 jobs at MG Rover's Midlands plant may be cut if investment in the firm goes ahead. a tie-up, seen as Rover's last chance to save its longbridge plant, has been pushed by Chancellor. a tie-up, seen as Rover's last chance to save its longbridge plant, has been pushed by Chancellor.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): pre-tax profits rose 15% from a year ago to reach £546m ($1.04bn) the firm's operating margins were 14.1%, which could reach 14.8% by 2006. analysts say the unit sell could sell for up to £350m.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): foreign firms have been given an extra year to meet tough new corporate governance regulations. many foreign firms had protested that the SEC was imposing an unfair burden. the new rules are the result of the Sarbanes-Oxley Act, part of the US clean-up.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): japanese mogul arrested on charges of falsifying shareholder information and selling shares. he was once ranked as the world's richest man and ran a business spanning hotels, railways, construction and a baseball team. he was taken away in a van outside one of his Prince hotels in Tokyo.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): net profit came in at 1.4bn euros (£960m; $1.85bn), a dramatic change from the loss of 364m euros in 2003. sales of stakes in firms including Russia's OAO mobile Telesystems raised 1.17bn euros. a year ago, debt was more than 11bn euros higher.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the italian liqueur maker will acquire shares from the Yantai State Asset Management Bureau. wine sales in 2003 up 25% at 61.1bn yuan. china is encouraging state-owned companies to sell shares to foreign investors.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): Umbro profits lifted by euro 2004 sportswear firm boosted by the tournament. pre-tax profit for 2004 was £15.4m ($29.4m) it hopes 2005 sales will benefit from the launch of a new England replica shirt.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the government program faces severe financial strains in coming decades. he called on congress to cut promised benefits for retirees. he also urged congress to reinstate lapsed rules that require tax cuts.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the mining group reported losses had deepened to £51.6m in 2004 from £1.2m. the company blamed geological problems, industrial action and \"operating flaws\" the company said it hoped to return to profit in 2006.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the move comes as the conservative country inches open the door to working women. the move comes as the conservative country inches open the door to working women. he told government departments to put plans in place for employing women.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): the government revised growth figures from earlier in 2004. a previous estimate of 0.1% growth between July and September was downgraded to 0.3% decline. a recession is commonly defined as two consecutive quarters of negative growth.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): crude futures jumped to $53.09 a barrel in new york before closing at $53.03. the jump followed a fire at Western Refining Company's refinery in Texas. a refinery in Houston was closed due to mechanical problems.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): production dropped 1.6% in October, reflecting a decline in exports. unemployment levels edged up 0.1% to 4.7%, slightly higher than forecast. the economy has grown for six quarters but growth slowed dramatically in the last quarter.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): budget airline Ryanair has placed an order for 70 Boeing 737-800 planes. the deal is valued at $4bn (£2.1bn) which should lead to 2,500 new jobs. the airline said the new planes would help it to cut operating costs further.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): creditors' debts expected to be converted into shares through two new share issues. the company's creditors will be asked to vote on the plan later this year. the plan is likely to give creditors of Parmalat Finanziaria shares worth about 5.7% of the debts they are owed.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): german car maker has announced £100m of new investment in mini production. some 200 new jobs are to be created at the Oxford factory. the result of the investment could be to raise output to more than 200,000 cars from 2007.\n",
      "Error calculating METEOR score: \"hypothesis\" expects pre-tokenized hypothesis (Iterable[str]): bad weather, rising raw material costs and the sluggish european economy hit sales at Nestle. revenues dipped 1.4% to 86.7bn Swiss francs in 2004 as sales of ice cream and mineral water were dampened by the wet summer. the strength of the Swiss franc against the US dollar, the disposal of businesses and challenging trading conditions in Europe all dented sales.\n",
      "Average METEOR Score: 0.0\n",
      "All scores saved to all_scores_Q2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "\n",
    "#define the path to the CSV file containing actual and predicted summaries\n",
    "csv_file_path = \"business_summaries_t5.csv\"\n",
    "\n",
    "#load BERTScore and ROUGE\n",
    "bertscore = load(\"bertscore\")\n",
    "rouge = load('rouge')\n",
    "\n",
    "#read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "#extract actual and predicted values\n",
    "actual_summaries = df[\"Actual\"].tolist()\n",
    "predicted_summaries = df[\"Predicted\"].tolist()\n",
    "\n",
    "#initialize lists to store scores\n",
    "bert_precision_scores = []\n",
    "bert_recall_scores = []\n",
    "bert_f1_scores = []\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "rouge_lsum_scores = []\n",
    "bleu_scores = []\n",
    "meteor_scores = []\n",
    "\n",
    "#compute scores for each pair of actual and predicted summaries\n",
    "for actual, predicted in zip(actual_summaries, predicted_summaries):\n",
    "    #compute BERTScores\n",
    "    bert_results = bertscore.compute(predictions=[predicted], references=[actual], model_type=\"distilbert-base-uncased\")\n",
    "    bert_precision_scores.append(bert_results[\"precision\"])\n",
    "    bert_recall_scores.append(bert_results[\"recall\"])\n",
    "    bert_f1_scores.append(bert_results[\"f1\"])\n",
    "\n",
    "    #compute ROUGE scores\n",
    "    rouge_result = rouge.compute(predictions=[predicted], references=[actual])\n",
    "\n",
    "    rouge_1_scores.append(rouge_result['rouge1'])\n",
    "    rouge_2_scores.append(rouge_result['rouge2'])\n",
    "    rouge_l_scores.append(rouge_result['rougeL'])\n",
    "    rouge_lsum_scores.append(rouge_result['rougeLsum'])\n",
    "\n",
    "    #compute BLEU score\n",
    "    references = [actual.split()]  #assuming the reference is a list of words\n",
    "    predicted_tokens = predicted.split()\n",
    "    bleu_score = sentence_bleu(references, predicted_tokens)\n",
    "    bleu_scores.append(bleu_score)\n",
    "\n",
    "    #compute METEOR score\n",
    "    try:\n",
    "        meteor_score = single_meteor_score(references[0], predicted)  #use the METEOR function\n",
    "        meteor_scores.append(meteor_score)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating METEOR score: {e}\")\n",
    "        meteor_scores.append(0.0)  #assign a default score of 0.0 for errors\n",
    "\n",
    "#create a new DataFrame to store all the scores\n",
    "scores_df = pd.DataFrame({\n",
    "    \"Actual\": actual_summaries,\n",
    "    \"Predicted\": predicted_summaries,\n",
    "    \"BERT Precision\": bert_precision_scores,\n",
    "    \"BERT Recall\": bert_recall_scores,\n",
    "    \"BERT F1\": bert_f1_scores,\n",
    "    \"ROUGE-1 F1\": rouge_1_scores,\n",
    "    \"ROUGE-2 F1\": rouge_2_scores,\n",
    "    \"ROUGE-L F1\": rouge_l_scores,\n",
    "    \"ROUGE-Lsum F1\": rouge_lsum_scores,\n",
    "    \"BLEU Score\": bleu_scores,\n",
    "    \"METEOR Score\": meteor_scores\n",
    "})\n",
    "\n",
    "#calculate and print the average METEOR score\n",
    "average_meteor_score = sum(meteor_scores) / len(meteor_scores)\n",
    "print(f\"Average METEOR Score: {average_meteor_score}\")\n",
    "\n",
    "#save all the scores to a new CSV file\n",
    "output_csv = \"all_scores_Q2.csv\"\n",
    "scores_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"All scores saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
