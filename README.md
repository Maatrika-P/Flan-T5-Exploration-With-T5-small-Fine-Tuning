# T5-Exploration-With-Flan-T5-Fine-Tuning ğŸ“š

This repository contains code and resources for an NLP project focused on text summarization using Flan-T5 and fine-tuning the T5-Small model. The project is organized into several directories and sections, each serving a specific purpose.

## Folder Structure ğŸ“

### Codes ğŸ’»

- **FlanT5_implementation**: Explore the Flan-T5 model for initial text summarization tasks.
- **T5Small_FineTuning**: Fine-tune the T5-Small model for customized text summarization.
- **FineTuned_T5_Small_Model**: Store the fine-tuned T5-Small model and its related files.

### Datasets ğŸ“‚

- **Original_Dataset**: Store the original text data used for the project.
- **Preprocessed_Data**: Contains preprocessed datasets and intermediate files for model training.

### Evaluation Scores ğŸ“Š

- **all_scores_Flan-T5**: Keep the evaluation scores obtained using the Flan-T5 model.
- **all_scores_T5-small**: Store evaluation scores after fine-tuning the T5-Small model.

### SMA_Final_Report ğŸ“
- Consists of more details about teh scores and the dataset for better understanding

## Getting Started ğŸš€

If you want to replicate the project or work with the provided code, follow these instructions:

1. Clone this repository to your local machine.
2. Explore the `Codes` directory to understand the project code and use cases.
3. Use the `Datasets` directory to access the original and preprocessed data.
4. Check the evaluation scores in the `Evaluation Scores` directory for performance insights.
5. Find more details in the `SMA_Final_Report` regarding evaluated scores and the datasets used

## Usage ğŸ§¾

- Detailed explanations of how to run and use the code can be found in the individual `Codes` directories.

## Contributors ğŸ™Œ

- List any contributors or team members who participated in the project.

## License ğŸ“

- Describe the project's licensing information.

## Acknowledgments ğŸ™

ğŸ™Œ We would like to extend our gratitude to the following individuals and organizations for their valuable contributions and support throughout this project:

- **Hugging Face Transformers** for providing state-of-the-art pre-trained language models and tools that made my exploration and fine-tuning process more efficient.

- **OpenAI** for developing and sharing the GPT-3.5-based assistant that provided guidance and assistance during my work.


Enjoy exploring and utilizing this project! ğŸŒŸ
